{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVW5Nezc8GZ"
      },
      "source": [
        "# 3. Basic models from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "  - Install Conda and create environment: see notebook *1. Conda setup*\n",
        "  - Install Poetry and create configuration: see notebook *2. Poetry setup*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure you select the environment (kernel) *NN* to run this notebook. Also activate it in companion terminal:  \n",
        "`conda activate NN`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check we have Python 3.9 running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGkS6nN6dQaz",
        "outputId": "f49e39b2-eb9a-4d27-82bf-b19a58367a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.9.7\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's make sure packages and dependencies are installed by Poetry:  \n",
        "```poetry install```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check our packages and dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngcaTx9Y-1lX",
        "outputId": "53a7f8bf-cb40-4d98-da60-3cbfe097fc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36mmatplotlib\u001b[0m \u001b[1m3.5.1\u001b[0m Python plotting package\n",
            "├── \u001b[33mcycler\u001b[0m >=0.10\n",
            "├── \u001b[33mfonttools\u001b[0m >=4.22.0\n",
            "├── \u001b[33mkiwisolver\u001b[0m >=1.0.1\n",
            "├── \u001b[33mnumpy\u001b[0m >=1.17\n",
            "├── \u001b[33mpackaging\u001b[0m >=20.0\n",
            "│   └── \u001b[32mpyparsing\u001b[0m >=2.0.2,<3.0.5 || >3.0.5 \n",
            "├── \u001b[33mpillow\u001b[0m >=6.2.0\n",
            "├── \u001b[33mpyparsing\u001b[0m >=2.2.1\n",
            "├── \u001b[33mpython-dateutil\u001b[0m >=2.7\n",
            "│   └── \u001b[32msix\u001b[0m >=1.5 \n",
            "└── \u001b[33msetuptools-scm\u001b[0m >=4\n",
            "    ├── \u001b[32mpackaging\u001b[0m >=20.0 \n",
            "    │   └── \u001b[35mpyparsing\u001b[0m >=2.0.2,<3.0.5 || >3.0.5 \n",
            "    └── \u001b[32mtomli\u001b[0m >=1.0.0 \n",
            "\u001b[36mnumpy\u001b[0m \u001b[1m1.22.1\u001b[0m NumPy is the fundamental package for array computing with Python.\n",
            "\u001b[36mpytest\u001b[0m \u001b[1m6.2.5\u001b[0m pytest: simple powerful testing with Python\n",
            "├── \u001b[33matomicwrites\u001b[0m >=1.0\n",
            "├── \u001b[33mattrs\u001b[0m >=19.2.0\n",
            "├── \u001b[33mcolorama\u001b[0m *\n",
            "├── \u001b[33miniconfig\u001b[0m *\n",
            "├── \u001b[33mpackaging\u001b[0m *\n",
            "│   └── \u001b[32mpyparsing\u001b[0m >=2.0.2,<3.0.5 || >3.0.5 \n",
            "├── \u001b[33mpluggy\u001b[0m >=0.12,<2.0\n",
            "├── \u001b[33mpy\u001b[0m >=1.8.2\n",
            "└── \u001b[33mtoml\u001b[0m *\n",
            "\u001b[36mtorch\u001b[0m \u001b[1m1.10.1\u001b[0m Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "└── \u001b[33mtyping-extensions\u001b[0m *\n"
          ]
        }
      ],
      "source": [
        "!poetry show --tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to update the Conda environment, we can run (in companion terminal):  \n",
        "```\n",
        "conda env update --prune -f environment_init.yml\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to update the Poetry setup, we can run (in companion terminal, making sure NN is activated):  \n",
        "```\n",
        "poetry update\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can create shortcuts for these actions in a separate **Makefile** (check its contents), which can then be called from a terminal:\n",
        "```\n",
        "make conda-udate\n",
        "make poetry-update\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CuuBRbRdXDJ"
      },
      "source": [
        "## 1D Linear model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: This notebook is inspired from https://fullstackdeeplearning.com/spring2021/notebook-1/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate and visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us create and show a dataset of 20 points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ZhJh0fUDdIlo",
        "outputId": "6658426c-f154-4bf3-eb28-a21091b5b469"
      },
      "outputs": [],
      "source": [
        "n = 20\n",
        "d = 1\n",
        "x = np.random.uniform(-1, 1, (n, d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose that we want to approximate the 'true' function h(x) = 5x + 10:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights_true = np.array([[5],])\n",
        "bias_true = np.array([10])\n",
        "\n",
        "y_true = x @ weights_true + bias_true # Matrix multiplication and element-wise addition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect all the shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: (20, 1), weights: (1, 1), bias: (1,), y: (20, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f'x: {x.shape}, weights: {weights_true.shape}, bias: {bias_true.shape}, y: {y_true.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot our true function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fde2e24fee0>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib.pyplot import figure\n",
        "figure(figsize=(8, 6), dpi=100)\n",
        "plt.plot(x, y_true, 'b--', label='true function')\n",
        "plt.plot(x, y_true, 'rx')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKASk4TeP-Vu"
      },
      "source": [
        "### Linear model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "rpaA6KL1AzUe",
        "outputId": "af85d4ed-1972-4d54-fd0e-758160896961"
      },
      "outputs": [],
      "source": [
        "class LinearNN:\n",
        "  def __init__(self, input_dim, num_hidden=1):\n",
        "    self.weights = np.random.randn(input_dim, num_hidden) * np.sqrt(2. / input_dim)\n",
        "    self.bias = np.zeros(num_hidden)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    return x @ self.weights + self.bias\n",
        "\n",
        "linear = Linear(d)\n",
        "y_pred = linear(x)\n",
        "plt.plot(x, y_true, marker='x', label='underlying function')\n",
        "plt.scatter(x, y_pred, color='r', marker='.', label='our function')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtKQdlViQBm_"
      },
      "source": [
        "### Basic loss function: MSE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIn86q0oDNsy",
        "outputId": "756200f6-7830-43c4-bd27-9119d23f3f60"
      },
      "outputs": [],
      "source": [
        "# How wrong are these initial predictions, exactly?\n",
        "# It's up to us, and our definition is called the loss function.\n",
        "# Let's use Mean Squared Error (MSE) as our loss function.\n",
        "\n",
        "class MSE:\n",
        "  def __call__(self, y_pred, y_true):\n",
        "    self.y_pred = y_pred\n",
        "    self.y_true = y_true\n",
        "    return ((y_true - y_pred) ** 2).mean()\n",
        "  \n",
        "loss = MSE()\n",
        "print(f'Our initial loss is {loss(y_pred, y_true)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMJrVabQRbBp"
      },
      "source": [
        "### Add back propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNw1AvS0ArB3"
      },
      "outputs": [],
      "source": [
        "# Let's use gradient descent to learn the weights and bias that minimizes the loss function.\n",
        "# For this, we need the gradient of the loss function and the gradients of the linear function.\n",
        "\n",
        "class MSE:\n",
        "  def __call__(self, y_pred, y_true):\n",
        "    self.y_pred = y_pred\n",
        "    self.y_true = y_true\n",
        "    return ((y_pred - y_true) ** 2).mean()\n",
        "\n",
        "  def backward(self):\n",
        "    n = self.y_true.shape[0]\n",
        "    self.gradient = 2. * (self.y_pred - self.y_true) / n\n",
        "    # print('MSE backward', self.y_pred.shape, self.y_true.shape, self.gradient.shape)\n",
        "    return self.gradient\n",
        "\n",
        "\n",
        "class Linear:\n",
        "  def __init__(self, input_dim: int, num_hidden: int = 1):\n",
        "    self.weights = np.random.randn(input_dim, num_hidden) * np.sqrt(2. / input_dim)\n",
        "    self.bias = np.zeros(num_hidden)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    self.x = x\n",
        "    output = x @ self.weights + self.bias\n",
        "    return output\n",
        "\n",
        "  def backward(self, gradient):\n",
        "    self.weights_gradient = self.x.T @ gradient\n",
        "    self.bias_gradient = gradient.sum(axis=0)\n",
        "    self.x_gradient = gradient @ self.weights.T\n",
        "    return self.x_gradient\n",
        "\n",
        "  def update(self, lr):\n",
        "    self.weights = self.weights - lr * self.weights_gradient\n",
        "    self.bias = self.bias - lr * self.bias_gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NcA_JDXJ6rR",
        "outputId": "4b109598-71d9-41f9-82f8-262c7e5d114e"
      },
      "outputs": [],
      "source": [
        "# Take one step forward and one step backward to make sure nothing breaks, and that the loss decreases.\n",
        "loss = MSE()\n",
        "linear = Linear(d)\n",
        "y_pred = linear(x)\n",
        "print(loss(y_pred, y_true))\n",
        "loss_gradient = loss.backward()\n",
        "linear.backward(loss_gradient)\n",
        "linear.update(0.1)\n",
        "y_pred = linear(x)\n",
        "print(loss(y_pred, y_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoyuH3gCRjGp"
      },
      "source": [
        "### Train using gradient descent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "qE__Ygl2c4IS",
        "outputId": "4f6ecd59-7b83-46a4-a595-aa729e08b5dc"
      },
      "outputs": [],
      "source": [
        "plt.plot(x, y_true, marker='x', label='underlying function')\n",
        "\n",
        "loss = MSE()\n",
        "linear = Linear(d)\n",
        "\n",
        "num_epochs = 40\n",
        "lr = 0.1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  y_pred = linear(x)\n",
        "  loss_value = loss(y_pred, y_true)\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    print(f'Epoch {epoch}, loss {loss_value}')\n",
        "    plt.plot(x, y_pred.squeeze(), label=f'Epoch {epoch}')\n",
        "\n",
        "  gradient_from_loss = loss.backward()\n",
        "  linear.backward(gradient_from_loss)\n",
        "  linear.update(lr)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK1qniplRpxN"
      },
      "source": [
        "### 2-dimensional inputs work, too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "RWqEaOWqNbwV",
        "outputId": "05dc9030-9622-499b-c218-f23e45a23a8a"
      },
      "outputs": [],
      "source": [
        "# What about 2-dimensional x?\n",
        "\n",
        "n = 100\n",
        "d = 2\n",
        "x = np.random.uniform(-1, 1, (n, d))\n",
        "\n",
        "# y = w * x + b\n",
        "# y = w_0 * x_0 + w_1 * x_1 + b\n",
        "# y = w@x + b\n",
        "\n",
        "weights_true = np.array([[2, -1], ]).T\n",
        "bias_true = np.array([0.5])\n",
        "print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "y_true = x @ weights_true + bias_true\n",
        "print(f'x: {x.shape}, weights: {weights_true.shape}, bias: {bias_true.shape}, y: {y_true.shape}')\n",
        "\n",
        "def plot_3d(x, y, y_pred=None):\n",
        "  import matplotlib.pyplot as plt\n",
        "  from mpl_toolkits.mplot3d import Axes3D\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "  ax.scatter(x[:, 0], x[:, 1], y, label='underlying function')\n",
        "  if y_pred is not None:\n",
        "    ax.scatter(x[:, 0], x[:, 1], y_pred, label='our function')\n",
        "  plt.legend()\n",
        "\n",
        "plot_3d(x, y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "pZwGG7rAUJfe",
        "outputId": "768e5e4a-c3ee-4958-dd8a-e98a18886c6c"
      },
      "outputs": [],
      "source": [
        "loss = MSE()\n",
        "linear = Linear(2)\n",
        "y_pred = linear(x)\n",
        "print(loss(y_pred, y_true))\n",
        "fig = plot_3d(x, y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "ZydPQYKIUtNT",
        "outputId": "368cae8a-9a6a-46c2-efdf-fc338ea3d6b6"
      },
      "outputs": [],
      "source": [
        "from typing import Callable\n",
        "\n",
        "def fit(x: np.ndarray, y: np.ndarray, model: Callable, loss: Callable, lr: float, num_epochs: int):\n",
        "  for epoch in range(num_epochs):\n",
        "    y_pred = model(x)\n",
        "    loss_value = loss(y_pred, y)\n",
        "    print(f'Epoch {epoch}, loss {loss_value}')\n",
        "    gradient_from_loss = loss.backward()\n",
        "    model.backward(gradient_from_loss)\n",
        "    model.update(lr)\n",
        "\n",
        "fit(x, y_true, model=linear, loss=loss, lr=0.1, num_epochs=20)\n",
        "plot_3d(x, y_true, linear(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVZo5o9hdcia"
      },
      "source": [
        "## Basic regression with a Multi-layer Perceptron\n",
        "\n",
        "So, we now have a way to automatically fit a linear function to N-dimensional data.\n",
        "\n",
        "How can this be made to work for non-linear data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "cqENhTMpdlJT",
        "outputId": "a2a27ec5-5154-4028-808b-fece1a29259a"
      },
      "outputs": [],
      "source": [
        "# Make non-linear data\n",
        "\n",
        "n = 200\n",
        "d = 2\n",
        "x = np.random.uniform(-1, 1, (n, d))\n",
        "\n",
        "weights_true = np.array([[5, 1],]).T\n",
        "bias_true = np.array([1])\n",
        "\n",
        "y_true = (x ** 2) @ weights_true + x @ weights_true + bias_true\n",
        "print(f'x: {x.shape}, weights: {weights_true.shape}, bias: {bias_true.shape}, y: {y_true.shape}')\n",
        "\n",
        "plot_3d(x, y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "UgbM2NMJYswq",
        "outputId": "a32c91ce-f04b-455f-bfa0-a813ce409aff"
      },
      "outputs": [],
      "source": [
        "# We can train just fine, but the final loss will remain high, as our linear function is incapable\n",
        "# of representing the data.\n",
        "\n",
        "loss = MSE()\n",
        "linear = Linear(d)\n",
        "fit(x, y_true, model=linear, loss=loss, lr=0.1, num_epochs=40)\n",
        "plot_3d(x, y_true, linear(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-QK1DGMVFmV"
      },
      "source": [
        "### Add non-linearity: ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhGZIvzkYzar",
        "outputId": "6c87b0c3-81c3-4845-e8e6-5466f5026184"
      },
      "outputs": [],
      "source": [
        "# In order to learn non-linear functions, we need non-linearities in our model.\n",
        "\n",
        "class Relu:\n",
        "    def __call__(self, input_):\n",
        "        self.input_ = input_\n",
        "        self.output = np.clip(self.input_, 0, None)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, output_gradient):\n",
        "      # import pdb; pdb.set_trace()  # By the way, this is how you can debug\n",
        "      self.input_gradient = (self.input_ > 0) * output_gradient\n",
        "      return self.input_gradient\n",
        "\n",
        "\n",
        "relu = Relu()\n",
        "input_ = np.expand_dims(np.array([1, 0.5, 0, -0.5, -1]), -1)\n",
        "print(relu(input_))\n",
        "print(relu.backward(input_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c67k16FsVQUj"
      },
      "source": [
        "### Train our new non-linear model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "hyKYKhm0ZunK",
        "outputId": "eb47c706-80b2-4ef7-989d-cf4b0d01d56e"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "  def __init__(self, input_dim, num_hidden):\n",
        "    self.linear1 = Linear(input_dim, num_hidden)\n",
        "    self.relu = Relu()\n",
        "    self.linear2 = Linear(num_hidden, 1)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    l1 = self.linear1(x)\n",
        "    r = self.relu(l1)\n",
        "    l2 = self.linear2(r)\n",
        "    return l2\n",
        "  \n",
        "  def backward(self, output_gradient):\n",
        "    linear2_gradient = self.linear2.backward(output_gradient)\n",
        "    relu_gradient = self.relu.backward(linear2_gradient)\n",
        "    linear1_gradient = self.linear1.backward(relu_gradient)\n",
        "    # print('Model backward', linear2_gradient.shape, relu_gradient.shape, linear1_gradient.shape)\n",
        "    # import pdb; pdb.set_trace()\n",
        "    return linear1_gradient\n",
        "\n",
        "  def update(self, lr):\n",
        "    self.linear2.update(lr)\n",
        "    self.linear1.update(lr)\n",
        "\n",
        "loss = MSE()\n",
        "model = Model(d, 10)\n",
        "y_pred = model(x)\n",
        "loss_value = loss(y_pred, y_true)\n",
        "loss_gradient = loss.backward()\n",
        "print(loss_value)\n",
        "model.backward(loss_gradient)\n",
        "plot_3d(x, y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKJ4L0-WfYrd",
        "outputId": "8484df11-cdc2-40f7-8441-cef64ebcf4bd"
      },
      "outputs": [],
      "source": [
        "# Test just one forward and backward step\n",
        "loss = MSE()\n",
        "model = Model(d, 10)\n",
        "y_pred = model(x)\n",
        "loss_value = loss(y_pred, y_true)\n",
        "print(loss_value)\n",
        "loss_gradient = loss.backward()\n",
        "model.backward(loss_gradient)\n",
        "model.update(0.1)\n",
        "y_pred = model(x)\n",
        "loss_value = loss(y_pred, y_true)\n",
        "print(loss_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "wllnmL6Sbsh6",
        "outputId": "f634d39c-58cd-4e95-fa91-1cd139c6d81c"
      },
      "outputs": [],
      "source": [
        "fit(x, y_true, model=model, loss=loss, lr=0.1, num_epochs=40)\n",
        "plot_3d(x, y_true, model(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq0Z_14tdra9"
      },
      "source": [
        "### Same thing, in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUzGijLkOUiy",
        "outputId": "18e32079-c249-4dbf-bb02-8e59e7fe4521"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class TorchModel(nn.Module):\n",
        "  def __init__(self, input_dim, num_hidden):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, num_hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(num_hidden, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    l1 = self.linear1(x)\n",
        "    r = self.relu(l1)\n",
        "    l2 = self.linear2(r)\n",
        "    return l2\n",
        "\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "model = TorchModel(d, 10)\n",
        "x_tensor = torch.tensor(x).float()\n",
        "y_true_tensor = torch.tensor(y_true).float()\n",
        "y_pred_tensor = model(x_tensor)\n",
        "loss_value = loss(y_pred_tensor, y_true_tensor)\n",
        "print(loss_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDoKS0BBYlxU",
        "outputId": "84c60291-28a0-40c1-c6d8-716e6440d798"
      },
      "outputs": [],
      "source": [
        "# Test just one forward and backward step\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "y_pred_tensor = model(x_tensor)\n",
        "loss_value = loss(y_pred_tensor, y_true_tensor)\n",
        "print(loss_value)\n",
        "loss_gradient = loss_value.backward()\n",
        "optimizer.step()\n",
        "\n",
        "y_pred_tensor = model(x_tensor)\n",
        "loss_value = loss(y_pred_tensor, y_true_tensor)\n",
        "print(loss_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "Yx8hOdiRcIEJ",
        "outputId": "5682aabf-8e5a-4390-a636-b093fbf6b315"
      },
      "outputs": [],
      "source": [
        "# Now we run the training loop\n",
        "\n",
        "def torch_fit(x: np.ndarray, y: np.ndarray, model: Callable, loss: Callable, lr: float, num_epochs: int):\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "  for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred_tensor = model(x_tensor)\n",
        "    loss_value = loss(y_pred_tensor, y_true_tensor)\n",
        "    print(loss_value)\n",
        "    loss_value.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "torch_fit(x_tensor, y_true_tensor, model=model, loss=loss, lr=0.1, num_epochs=40)\n",
        "plot_3d(x, y_true, model(x_tensor).detach())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo5zDlScdl4s"
      },
      "source": [
        "### Same thing, in Tensorflow/Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "HDoGEt6RnvCU",
        "outputId": "fea43c55-34f9-4c9c-ff0d-446c4853e280"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "inputs = keras.Input(shape=(2,))\n",
        "l1 = layers.Dense(10, activation='relu', name='dense_1')(inputs)\n",
        "outputs = layers.Dense(1, name='regression')(l1)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "print(model.summary())\n",
        "model.compile(loss='mse', optimizer=optimizers.SGD(0.1))\n",
        "\n",
        "model.fit(x, y_true, epochs=10)\n",
        "\n",
        "y_pred = model.predict(x)\n",
        "\n",
        "plot_3d(x, y_true, model(x))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "deep_learning_fundamentals_part1",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
